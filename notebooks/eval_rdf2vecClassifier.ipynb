{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edae41f5-8379-478a-80b4-8703c94916fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "from settings import VECTOR_SIZE,  CLASSIFIER_EPOCHS\n",
    "from utils_graph import parse_rdflib_to_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97199e0-c550-49f1-a095-5ef70d0497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word_vectors = Word2Vec.load('walks/model').wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0810bf13-53a4-4829-b1af-6137f2e2029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/otautz/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found trained model! Loading :)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from models import ClassifierSimple\n",
    "import torch\n",
    "model = ClassifierSimple()    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if Path('rdf2vecClassfier.pth').is_file():\n",
    "    print('found trained model! Loading :)')\n",
    "    model.load_state_dict(torch.load('rdf2vecClassfier.pth'))\n",
    "    history = pd.read_csv('log.csv')\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print('model not found. Train it with ''train_rdf2vec_classifier.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c23be91-0434-4bcb-a209-1f3a0ca8a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 270 triples from training set\n",
      "removed 35 triples from validation set\n",
      "removed 61 triples from test set\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "from utils_graph import clean_graph, get_entities\n",
    "\n",
    "\n",
    "g_train = Graph()\n",
    "g_val = Graph()\n",
    "g_test = Graph()\n",
    "\n",
    "g_train = g_train.parse('FB15k-237/train.nt', format='nt')\n",
    "g_val   = g_val.parse('FB15k-237/valid.nt', format='nt')\n",
    "g_test  = g_test.parse('FB15k-237/test.nt', format='nt')\n",
    "\n",
    "\n",
    "# clean graphs \n",
    "# number of triples removed should be low, a few hundred\n",
    "print(f\"removed {clean_graph(g_train,word_vectors)} triples from training set\")\n",
    "print(f\"removed {clean_graph(g_val,word_vectors)} triples from validation set\")\n",
    "print(f\"removed {clean_graph(g_test,word_vectors)} triples from test set\")\n",
    "\n",
    "entities = get_entities((g_train,g_val,g_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72176004-0f5e-4db3-b76c-6defc6512dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_eval import eval_ranks, mean_rank, mean_reciprocal_rank, hitsAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326df1e8-9211-4667-bc3e-e8db01a68457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b6dcba-40c6-4c16-a9c1-3ba95c7e06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [1:07:31<00:00, 17.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR\t[100.34046936035156]\n",
      "MRR\t[0.6825782656669617]\n",
      "Hits@1\t[0.28289833664894104]\n",
      "Hits@3\t[0.4160054326057434]\n",
      "Hits@10\t[0.5686512589454651]\n",
      "MR_head\t[67.42181396484375]\n",
      "MRR_head\t[0.7664385437965393]\n",
      "Hits@1_head\t[0.3181592524051666]\n",
      "Hits@3_head\t[0.4730563461780548]\n",
      "Hits@10_head\t[0.633588969707489]\n",
      "MR_tail\t[133.25912475585938]\n",
      "MRR_tail\t[0.598717987537384]\n",
      "Hits@1_tail\t[0.24763743579387665]\n",
      "Hits@3_tail\t[0.3589545488357544]\n",
      "Hits@10_tail\t[0.5037134885787964]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'preprocessing': 102.14475320791826,\n",
       " 'subgraph': 1.1769551234319806,\n",
       " 'collect_embeddings': 0.02276387019082904,\n",
       " 'copy embeddings into array': 720.8355533811264,\n",
       " 'score_embeddings': 3226.3337846915238,\n",
       " 'rank_embeddings': 103.31181812100112}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tested scoring on cpu\n",
    "import gc\n",
    "from utils_eval import eval_model\n",
    "torch.set_num_threads(32)\n",
    "   \n",
    "\n",
    "stats, pt = eval_model(model,g_train,lambda x: word_vectors[x])\n",
    "\n",
    "for k,v in stats.items():\n",
    "    print(f\"{k}\\t{v}\")\n",
    "    \n",
    "pd.DataFrame(stats).to_csv('rdf2vec_train_scores.csv')\n",
    "pt.stats_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81aab68c-6928-4c92-98a6-e0d716cf90b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [12:56<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR\t[329.9128723144531]\n",
      "MRR\t[0.33454519510269165]\n",
      "Hits@1\t[0.1241428554058075]\n",
      "Hits@3\t[0.21882857382297516]\n",
      "Hits@10\t[0.3336285650730133]\n",
      "MR_head\t[185.71273803710938]\n",
      "MRR_head\t[0.43780481815338135]\n",
      "Hits@1_head\t[0.1638857126235962]\n",
      "Hits@3_head\t[0.29280000925064087]\n",
      "Hits@10_head\t[0.4277714192867279]\n",
      "MR_tail\t[474.1130065917969]\n",
      "MRR_tail\t[0.23128560185432434]\n",
      "Hits@1_tail\t[0.0843999981880188]\n",
      "Hits@3_tail\t[0.14485713839530945]\n",
      "Hits@10_tail\t[0.2394857108592987]\n"
     ]
    }
   ],
   "source": [
    "stats, pt = eval_model(model,g_val,lambda x: word_vectors[x])\n",
    "\n",
    "for k,v in stats.items():\n",
    "    print(f\"{k}\\t{v}\")\n",
    "pt.stats_sum()\n",
    "\n",
    "pd.DataFrame(stats).to_csv('rdf2vec_val_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ea1fd0-227c-43d6-af06-def322bf8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [13:52<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR\t[344.34423828125]\n",
      "MRR\t[0.339802086353302]\n",
      "Hits@1\t[0.12793433666229248]\n",
      "Hits@3\t[0.2197255641222]\n",
      "Hits@10\t[0.3298211097717285]\n",
      "MR_head\t[196.85157775878906]\n",
      "MRR_head\t[0.46707841753959656]\n",
      "Hits@1_head\t[0.18142612278461456]\n",
      "Hits@3_head\t[0.3021318316459656]\n",
      "Hits@10_head\t[0.42822837829589844]\n",
      "MR_tail\t[491.8369140625]\n",
      "MRR_tail\t[0.21252577006816864]\n",
      "Hits@1_tail\t[0.0744425356388092]\n",
      "Hits@3_tail\t[0.13731928169727325]\n",
      "Hits@10_tail\t[0.23141387104988098]\n"
     ]
    }
   ],
   "source": [
    "stats, pt = eval_model(model,g_test,lambda x: word_vectors[x])\n",
    "\n",
    "for k,v in stats.items():\n",
    "    print(f\"{k}\\t{v}\")\n",
    "pt.stats_sum()\n",
    "pd.DataFrame(stats).to_csv('rdf2vec_test_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b804d81-a84d-477e-b0ff-ef279b1d1d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MR': [344.34423828125],\n",
       " 'MRR': [0.339802086353302],\n",
       " 'Hits@1': [0.12793433666229248],\n",
       " 'Hits@3': [0.2197255641222],\n",
       " 'Hits@10': [0.3298211097717285],\n",
       " 'MR_head': [196.85157775878906],\n",
       " 'MRR_head': [0.46707841753959656],\n",
       " 'Hits@1_head': [0.18142612278461456],\n",
       " 'Hits@3_head': [0.3021318316459656],\n",
       " 'Hits@10_head': [0.42822837829589844],\n",
       " 'MR_tail': [491.8369140625],\n",
       " 'MRR_tail': [0.21252577006816864],\n",
       " 'Hits@1_tail': [0.0744425356388092],\n",
       " 'Hits@3_tail': [0.13731928169727325],\n",
       " 'Hits@10_tail': [0.23141387104988098]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
