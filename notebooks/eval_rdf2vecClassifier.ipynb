{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edae41f5-8379-478a-80b4-8703c94916fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "from settings import VECTOR_SIZE,  CLASSIFIER_EPOCHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97199e0-c550-49f1-a095-5ef70d0497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word_vectors = Word2Vec.load('walks/model').wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0810bf13-53a4-4829-b1af-6137f2e2029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 15:16:39.136467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-17 15:16:39.136488: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found trained model! Loading :)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from models import ClassifierSimple\n",
    "import torch\n",
    "model = ClassifierSimple()    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if Path('rdf2vecClassfier.pth').is_file():\n",
    "    print('found trained model! Loading :)')\n",
    "    model.load_state_dict(torch.load('rdf2vecClassfier.pth'))\n",
    "    history = pd.read_csv('log.csv')\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print('model not found. Train it with ''train_rdf2vec_classifier.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c23be91-0434-4bcb-a209-1f3a0ca8a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 2 triples from training set\n",
      "removed 2 triples from validation set\n",
      "removed 0 triples from test set\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "from utils_graph import clean_graph, get_entities\n",
    "\n",
    "\n",
    "g_train = Graph()\n",
    "g_val = Graph()\n",
    "g_test = Graph()\n",
    "\n",
    "g_train = g_train.parse('FB15k-237/train_1000.nt', format='nt')\n",
    "g_val   = g_val.parse('FB15k-237/valid_1000.nt', format='nt')\n",
    "g_test  = g_test.parse('FB15k-237/test_1000.nt', format='nt')\n",
    "\n",
    "\n",
    "# clean graphs \n",
    "# number of triples removed should be low, a few hundred\n",
    "print(f\"removed {clean_graph(g_train,word_vectors)} triples from training set\")\n",
    "print(f\"removed {clean_graph(g_val,word_vectors)} triples from validation set\")\n",
    "print(f\"removed {clean_graph(g_test,word_vectors)} triples from test set\")\n",
    "\n",
    "entities = get_entities((g_train,g_val,g_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72176004-0f5e-4db3-b76c-6defc6512dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_eval import eval_ranks, mean_rank, mean_reciprocal_rank, hitsAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6dcba-40c6-4c16-a9c1-3ba95c7e06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                              | 26/156 [00:30<02:29,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "# tested scoring on cpu\n",
    "import gc\n",
    "torch.set_num_threads(32)\n",
    "with torch.no_grad():\n",
    "    head_ranks, tail_ranks,pt = eval_ranks(model,g_train,lambda x: word_vectors[x],force_cpu=True,filtered=True,bit16tensors=False)\n",
    "    \n",
    "    print(f\"MR: {mean_rank(head_ranks, tail_ranks)}\")\n",
    "    print(f\"MRR: {mean_reciprocal_rank(head_ranks, tail_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1: {hitsAt(head_ranks, tail_ranks,1)}\")\n",
    "    print(f\"H@3: {hitsAt(head_ranks, tail_ranks,3)}\")\n",
    "    print(f\"H@10: {hitsAt(head_ranks, tail_ranks,10)}\")\n",
    "    \n",
    "    \n",
    "    print(f\"MR_head: {torch.mean(head_ranks)}\")\n",
    "    print(f\"MRR_head: {torch.mean(1/head_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1_head: {(head_ranks <= 1).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@3_head: {(head_ranks <= 3).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@10_head: {(head_ranks <= 10).sum()/len(tail_ranks)}\")\n",
    "    \n",
    "    \n",
    "    print(f\"MR_tail: {torch.mean(tail_ranks)}\")\n",
    "    print(f\"MRR_tail: {torch.mean(1/tail_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1_tail: {(tail_ranks <= 1).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@3_tail: {(tail_ranks <= 3).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@10_tail: {(tail_ranks <= 10).sum()/len(tail_ranks)}\")\n",
    "    \n",
    "    \n",
    "gc.collect()\n",
    "pt.stats_sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab68c-6928-4c92-98a6-e0d716cf90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('here!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "std-env",
   "language": "python",
   "name": "std-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
